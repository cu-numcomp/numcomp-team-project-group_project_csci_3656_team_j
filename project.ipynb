{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Project: **Regression Methods** in **Real Estate**\n",
    "\n",
    "## Group members\n",
    "* Tanner Ball - Contributions: Source software, USA data, Methods section\n",
    "* Maximillian Audick - Contributions: Running tests, Introduction, Results and interpretation, Conclusion\n",
    "* Junyu Chen\n",
    "* Joseph McSoud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following prompts may be useful, but you don't have to use them.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project looked at the regression methods used in a github repository that sought to predict real estate prices using those regression methods. Regression is often used in attempts to predict market prices for things, be they stocks, commodities, or, in this case, real estate. Our team's goal was to determine how different data changes the reliability of the predictions from the various regression methods, and if any methods are indeed more reliable than the rest. To that end, we found data for average housing prices in the United States by zip code, cross-referenced this with average house square footage, and ran it through the methods. We then compared the results of our data to that of the repository's example data. In this report, we will cover the methods used in this repository and our results and conclusions from our test.\n",
    "\n",
    "## Methods\n",
    "* XGBoost Regression: XGBoost Regression uses a decision-tree-based algorithm that minimizes losses from adding new models. The algorithm makes use of the XGBoost library.\n",
    "* Random Forest Regression: Random Forest Regression creates multiple decision trees and outputs the mean prediction of each individual tree. This helps solve the problem of decision trees often overfitting to a training set.\n",
    "* Polynomial Regression: Polynomial Regression is a linear regression technique that models the non-linear relationship between the independent and dependent variables as an nth degree polynomial.\n",
    "* Neural Network MLP Regression: Neural Network MLP Regression is a form of neural network regression that involves backpropagation for training. Backpropagation allows the network to quickly calculate gradient descents for weights.\n",
    "* KNN Regression: KNN Regression, fully known as K-Nearest Neighbors Regression, predicts the value of an output based on the average value of the k-nearest values from a training set.\n",
    "* Ordinary Least-Squares Regression: Ordinary Least-Squares Regression estimates the unknown parameters in a linear regression model by minimizing the sum of the squared residuals, that is, the squared error between the linear model and the actual location of a value.\n",
    "* Ridge Regression: Ridge Regression, also known as Tikhonov Regularization, seeks to solve the issue of predictor variables often being highly correlated. This method adds a bias factor to each variable to help solve this problem.\n",
    "* Lasso Regression: Lasso Regression improves the prediction accuracy and interpretability of regression models. It does so by selecting only a certain subset of the covariates for the final model. By simplifying the model, it allows the model to be a little more understandable.\n",
    "\n",
    "## Results and interpretation\n",
    "\n",
    "The code contained data for housing prices in Amsterdam. We ran it to verify this data, then ran it again for housing data from across the United States. We found that the fit scores were, in general, much lower for this new data set than for the original one. Additionally, the score ordering changed to a large degree. The scoring results are enumerated as follows:\n",
    "\n",
    "#### XGBoost Regression:\n",
    "Amsterdam Data Score (Rank): 0.887 (1)\n",
    "\n",
    "USA Data Score (Rank): 0.035 (8)\n",
    "\n",
    "#### Random Forest Regression:\n",
    "Amsterdam Data Score (Rank): 0.839 (2)\n",
    "\n",
    "USA Data Score (Rank): 0.175 (3)\n",
    "\n",
    "#### Polynomial Regression:\n",
    "Amsterdam Data Score (Rank): 0.731 (3)\n",
    "\n",
    "USA Data Score (Rank): 0.163 (4)\n",
    "\n",
    "#### Neural Network MLP Regression:\n",
    "Amsterdam Data Score (Rank): 0.715 (4)\n",
    "\n",
    "USA Data Score (Rank): 0.237 (1)\n",
    "\n",
    "#### KNN Regression:\n",
    "Amsterdam Data Score (Rank): 0.711 (5)\n",
    "\n",
    "USA Data Score (Rank): 0.224 (2)\n",
    "\n",
    "#### Ordinary Least-Squares Regression:\n",
    "Amsterdam Data Score (Rank): 0.694 (6)\n",
    "\n",
    "USA Data Score (Rank): 0.134 (5)\n",
    "\n",
    "#### Ridge Regression:\n",
    "Amsterdam Data Score (Rank): 0.694 (7)\n",
    "\n",
    "USA Data Score (Rank): 0.107 (7)\n",
    "\n",
    "#### Lasso Regression:\n",
    "Amsterdam Data Score (Rank): 0.693 (8)\n",
    "\n",
    "USA Data Score (Rank): 0.134 (6)\n",
    "\n",
    "\n",
    "## Conclusions and open questions\n",
    "\n",
    "Random forest regression and MLP regression seem to perform the best overall, while ridge and lasso regression seem to perform the worst. Of note is that the XGBoost regression performed significantly worse for the USA housing price data. This is likely because of the fewer tuning parameters in this data set, as well as poor filter tuning to begin with.\n",
    "\n",
    "We had some questions regarding our findings:\n",
    "\n",
    "* Is fitting a linear regression to data really the best method for predicting housing prices?\n",
    "* Would more tunable parameters (i.e. more information about the houses) give better results?\n",
    "* Why did the author of this repository choose these specific tests?\n",
    "* Is the scoring algorithm used really the best representation of how effective each method is at providing a fit for the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
