{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Project: **Regression Methods** in **Real Estate**\n",
    "\n",
    "## Group members\n",
    "* Tanner Ball - Contributions: Source Software, USA Data, Methods section\n",
    "* Maximillian Audick\n",
    "* Junyu Chen\n",
    "* Joseph McSoud\n",
    "\n",
    "This notebook is a blank slate for you to write in.  Feel free to include figures (don't forget to add/commit them to your repository) and examples.  You can change the kernel (from `Python 3`; see upper right) if the open source project you're writing about does not use Python.  You can write from the prompts below or delete all the cells and start fresh.  Note that Git will always contain your history.\n",
    "\n",
    "You can run shell commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project.ipynb  README.md\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and include code snippets\n",
    "\n",
    "```c\n",
    "double square(double x) {\n",
    "    return x*x;\n",
    "}\n",
    "```\n",
    "or code cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square(3) = 9\n"
     ]
    }
   ],
   "source": [
    "def square(x):\n",
    "    return x*x\n",
    "\n",
    "print(f'square(3) = {square(3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Describe the objective of your study, citing prior work as appropriate (papers, websites, etc.).  There is no requirement on citation style, but please try to be consistent.\n",
    "\n",
    "## Methods\n",
    "* [XGBoost Regression:](#1)\n",
    "* [Random Forest Regression:](#2)\n",
    "* [Polynomial Regression:](#3)\n",
    "* [Neural Network MLP Regression:](#4)\n",
    "* [KNN Regression:](#5)\n",
    "* [Ordinary Least-Squares Regression:](#6)\n",
    "* [Ridge Regression:](#7)\n",
    "* [Lasso Regression:](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Results and interpretation\n",
    "\n",
    "The code contained data for housing prices in Amsterdam. We ran it to verify this data, then ran it again for housing data from across the United States. We found that the fit scores were, in general, much lower for this new data set than for the original one. Additionally, the score ordering changed to a large degree. The scoring results are enumerated as follows:\n",
    "\n",
    "#### XGBoost Regression:<a id='1'></a>\n",
    "Amsterdam Data Score (Rank): 0.887 (1)\n",
    "\n",
    "USA Data Score (Rank): 0.035 (8)\n",
    "\n",
    "#### Random Forest Regression:<a id='2'></a>\n",
    "Amsterdam Data Score (Rank): 0.839 (2)\n",
    "\n",
    "USA Data Score (Rank): 0.175 (3)\n",
    "\n",
    "#### Polynomial Regression:<a id='3'></a>\n",
    "Amsterdam Data Score (Rank): 0.731 (3)\n",
    "\n",
    "USA Data Score (Rank): 0.163 (4)\n",
    "\n",
    "#### Neural Network MLP Regression:<a id='4'></a>\n",
    "Amsterdam Data Score (Rank): 0.715 (4)\n",
    "\n",
    "USA Data Score (Rank): 0.237 (1)\n",
    "\n",
    "#### KNN Regression:<a id='5'></a>\n",
    "Amsterdam Data Score (Rank): 0.711 (5)\n",
    "\n",
    "USA Data Score (Rank): 0.224 (2)\n",
    "\n",
    "#### Ordinary Least-Squares Regression:<a id='6'></a>\n",
    "Amsterdam Data Score (Rank): 0.694 (6)\n",
    "\n",
    "USA Data Score (Rank): 0.134 (5)\n",
    "\n",
    "#### Ridge Regression:<a id='7'></a>\n",
    "Amsterdam Data Score (Rank): 0.694 (7)\n",
    "\n",
    "USA Data Score (Rank): 0.107 (7)\n",
    "\n",
    "#### Lasso Regression:<a id='8'></a>\n",
    "Amsterdam Data Score (Rank): 0.693 (8)\n",
    "\n",
    "USA Data Score (Rank): 0.134 (6)\n",
    "\n",
    "Random forest regression and MLP regression seem to perform the best overall, while ridge and lasso regression seem to perform the worst. Of note is that the XGBoost regression performed significantly worse for the USA housing price data. This is likely because of the fewer tuning parameters in this data set, as well as poor filter tuning to begin with.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ea01e0695d4d96bde9fb3f9efa0ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='file', options=('OLS.png', 'KNN.png', 'Ridge.png', 'Neural.png', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import os\n",
    "from IPython.display import Image\n",
    "@interact\n",
    "def show_images(file=os.listdir('USAGraphs/')):\n",
    "    display(Image('USAGraphs/'+file))\n",
    "    display(Image('AmsterdamGraphs/'+file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and open questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
